{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "963c98d7",
   "metadata": {},
   "source": [
    "# 출력층 설계 (Output layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e2039bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d566bc63",
   "metadata": {},
   "source": [
    "### 소프트맥스 오버플로우 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f523e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan]\n",
      "[0.09003057 0.24472847 0.66524096]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\AppData\\Local\\Temp\\ipykernel_6532\\1283896694.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  exp_z = np.exp(x)\n",
      "C:\\Users\\lemon\\AppData\\Local\\Temp\\ipykernel_6532\\1283896694.py:5: RuntimeWarning: invalid value encountered in divide\n",
      "  return exp_z / np.sum(exp_z)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    exp_z = np.exp(x)\n",
    "    return exp_z / np.sum(exp_z)\n",
    "\n",
    "def stable_softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z))\n",
    "    return exp_z / np.sum(exp_z)\n",
    "\n",
    "x = np.array([1000, 1001, 1002])\n",
    "print(softmax(x))\n",
    "print(stable_softmax(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c8d869",
   "metadata": {},
   "source": [
    "- pytorch 라이브러리 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "524d8d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n",
      "tensor([1., 1., 1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\AppData\\Local\\Temp\\ipykernel_6532\\2262784125.py:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  softmax_output = F.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F     # nn: neural network package\n",
    "\n",
    "x = torch.tensor([1000, 1001, 1002], dtype=torch.float32)   #  float로 datatype 맞춰줘야 함\n",
    "\n",
    "softmax_output = F.softmax(x)\n",
    "print(softmax_output)\n",
    "\n",
    "sigmoid_output = torch.sigmoid(x)\n",
    "print(sigmoid_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecbdca6",
   "metadata": {},
   "source": [
    "### 손실 함수와 연계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53024efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0821858644485474\n",
      "1.0582523345947266\n",
      "1.0349880456924438\n",
      "1.0123851299285889\n",
      "0.990421712398529\n",
      "0.9690577983856201\n",
      "0.9482390284538269\n",
      "0.9279109835624695\n",
      "0.9080328941345215\n",
      "0.8885785341262817\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 간단한 다중 클래스 분류 모델 정의\n",
    "class SimpleMultiClassModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleMultiClassModel, self).__init__()\n",
    "        self.fc = nn.Linear(5, 3)\n",
    "\n",
    "    # 순전파\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)   # fully connected 층\n",
    "\n",
    "# --> 구조 정의 하고 예측\n",
    "\n",
    "# 모델, 손실함수, 최적화함수 설정\n",
    "model = SimpleMultiClassModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)     \n",
    "\n",
    "# 데이터 생성\n",
    "inputs = torch.randn(4, 5)      # sample label data 4개\n",
    "labels = torch.tensor([0, 2, 1, 0])\n",
    "\n",
    "# 학습\n",
    "for _ in range(10):\n",
    "    preds = model(inputs)               # 순전파        model.forward(inputs)랑 똑같음\n",
    "    loss = criterion(preds, labels)     # 손실 계산\n",
    "    print(loss.item())                  # 손실값 출력\n",
    "\n",
    "    optimizer.zero_grad()               # 기울기 초기화 (이전 단계에서 계산된 기울기를 0으로 초기화)\n",
    "    loss.backward()                     # 손실에 대한 역전파 == 가중치 기울기 계산 (손실에 대한 역전파 수행 - 파라미터에 대한 기울기 계산)\n",
    "    optimizer.step()                    # 가중치 업데이트 (계산된 기울기를 사용하여 옵티마이저가 모델 파라미터 갱신)\n",
    "\n",
    "# 가중치가 업데이트 되면서 손실값 조금씩 줄어듦"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
